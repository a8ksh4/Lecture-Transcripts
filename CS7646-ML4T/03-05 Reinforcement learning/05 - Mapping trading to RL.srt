1
00:00:00,470 --> 00:00:02,920
Let's consider now
a little more carefully

2
00:00:02,920 --> 00:00:06,020
how we map trading to an RL problem.

3
00:00:06,020 --> 00:00:10,860
So first of all the environment
here is really the market.

4
00:00:10,860 --> 00:00:16,329
Our state that we're going to consider
includes things like market features,

5
00:00:16,329 --> 00:00:19,280
prices, whether we're holding the stock.

6
00:00:19,280 --> 00:00:21,690
I'll list a few of
those items right here.

7
00:00:21,690 --> 00:00:25,940
Our actions are things like buy and
sell, and

8
00:00:25,940 --> 00:00:30,220
potentially do nothing is
also an allowable action.

9
00:00:30,220 --> 00:00:32,659
So let's think about
this in the context of

10
00:00:32,659 --> 00:00:36,150
trying to learn how to
trade a particular stock.

11
00:00:36,150 --> 00:00:38,890
So we've got this
historical time series, and

12
00:00:38,890 --> 00:00:40,900
let's say this vertical line is today.

13
00:00:41,920 --> 00:00:46,830
Now we can look back over time
to infer the state of the stock.

14
00:00:46,830 --> 00:00:50,950
So what are the Ballinger Band
values and things like that.

15
00:00:50,950 --> 00:00:55,540
Now we process that and
decide what's our action.

16
00:00:55,540 --> 00:00:58,630
Let's suppose that we decide to buy.

17
00:00:58,630 --> 00:01:01,750
So once we buy, we're now holding long.

18
00:01:01,750 --> 00:01:02,880
That's part of our state.

19
00:01:03,900 --> 00:01:08,160
We go forward, we're now on a new
state where the price has gone up.

20
00:01:08,160 --> 00:01:11,960
We're holding long, lets suppose
we decide to sell at that point.

21
00:01:13,030 --> 00:01:14,440
So we've had two actions,

22
00:01:14,440 --> 00:01:19,600
well we've been in two states in
state one we were not holding.

23
00:01:19,600 --> 00:01:23,170
We executed the action by,
went forward in time,

24
00:01:23,170 --> 00:01:27,640
we're holding along now, and
then we execute the action sell.

25
00:01:27,640 --> 00:01:32,710
Note that we made money here and
that's our reward, r.

26
00:01:32,710 --> 00:01:34,540
So just to recap for a moment.

27
00:01:34,540 --> 00:01:40,605
The policy that we learn tells us what
to do at each time we evaluate state,

28
00:01:40,605 --> 00:01:42,365
and we're going to learn
that we haven't talked yet

29
00:01:42,365 --> 00:01:43,965
about how we learned the policy.

30
00:01:43,965 --> 00:01:47,675
But we're going to learn the policy
by looking at how we accrue money or

31
00:01:47,675 --> 00:01:50,125
don't based on the actions
we take in the environment.

